

# EfficentNet
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b0 --pretrained --sync-bn --loss focal --learning-rate 0.0001 --ycbcr --size 512 --batch-size 32 --loss-scale 128 --end-epoch 60
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b1 --pretrained --sync-bn --loss focal --learning-rate 0.0001 --ycbcr --size 512 --batch-size 32 --loss-scale 128 --end-epoch 60
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b2 --pretrained --sync-bn --loss focal --learning-rate 0.0001 --ycbcr --size 512 --batch-size 32 --loss-scale 128 --end-epoch 60
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b3 --pretrained --sync-bn --loss focal --learning-rate 0.0001 --ycbcr --size 512 --batch-size 32 --loss-scale 128 --end-epoch 60
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b4 --pretrained --sync-bn --loss focal --learning-rate 0.0001 --ycbcr --size 512 --batch-size 16 --loss-scale 128 --end-epoch 50
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b5 --pretrained --sync-bn --loss focal --learning-rate 0.0001 --ycbcr --size 512 --batch-size 16 --loss-scale 128 --end-epoch 50
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b6 --pretrained --sync-bn --loss focal --learning-rate 0.0001 --ycbcr --size 512 --batch-size 8  --loss-scale 128 --end-epoch 50
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b7 --pretrained --sync-bn --loss focal --learning-rate 0.0001 --ycbcr --size 512 --batch-size 8  --loss-scale 128 --end-epoch 50

# Train EfficentNet-b4
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b4 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 16 --loss-scale dynamic --end-epoch 60
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b4_label_smoothing_ycbcr_512_1.00e-03.pth --encoder efficientnet-b4 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 16 --loss-scale dynamic --end-epoch 20 --patience 1
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b4_label_smoothing_ycbcr_512_1.00e-03.pth --encoder efficientnet-b4 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 16 --loss-scale dynamic --end-epoch 20 --patience 1

# Train EfficentNet-b5
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b5 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --size 512 --batch-size 16 --loss-scale dynamic --end-epoch 20 --seed 1994
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b5_label_smoothing_rgb_512_1.00e-03.pth --encoder efficientnet-b5 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 16 --loss-scale dynamic --end-epoch 20 --seed 1994
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b5_label_smoothing_ycbcr_512_1.00e-03.pth --encoder efficientnet-b5 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 16 --loss-scale dynamic --end-epoch 20 --seed 1994
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b5_label_smoothing_ycbcr_512_1.00e-03.pth --encoder efficientnet-b5 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 16 --loss-scale dynamic --end-epoch 20 --seed 1994

# Train EfficentNet-b6
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b6 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --size 512 --batch-size 12 --loss-scale dynamic --end-epoch 1 --seed 3000
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b6_label_smoothing_rgb_512_1.00e-03.pth --encoder efficientnet-b6 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 12 --loss-scale dynamic --end-epoch 20 --seed 3000
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b6_label_smoothing_ycbcr_512_1.00e-03.pth --encoder efficientnet-b6 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 12 --loss-scale dynamic --end-epoch 20 --seed 3000
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b6_label_smoothing_ycbcr_512_1.00e-03.pth --encoder efficientnet-b6 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.001 --ycbcr --size 512 --batch-size 12 --loss-scale dynamic --end-epoch 20 --seed 3000

# Train EfficentNet-b7
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --encoder efficientnet-b7 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.0005 --size 512 --batch-size 8 --loss-scale dynamic --end-epoch 10
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b7_label_smoothing_rgb_512_1.00e-03.pth --encoder efficientnet-b7 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.0005 --ycbcr --size 512 --batch-size 8 --loss-scale dynamic --end-epoch 20
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b7_label_smoothing_ycbcr_512_1.00e-03.pth --encoder efficientnet-b7 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.0005 --ycbcr --size 512 --batch-size 8 --loss-scale dynamic --end-epoch 20
# python -m torch.distributed.launch --nproc_per_node=4 train.py --data /home/romanvlasov/junk/alaska2-image-steganalysis/input/train.csv --weights snapshots/efficientnet-b7_label_smoothing_ycbcr_512_1.00e-03.pth --encoder efficientnet-b7 --pretrained --sync-bn --loss label_smoothing --optimizer AdamW --learning-rate 0.0005 --ycbcr --size 512 --batch-size 8 --loss-scale dynamic --end-epoch 20

# python inference.py --ycbcr --encoder efficientnet-b3 --weight snapshots/efficientnet-b3_focal_512_1.00e-04.pth --submission submissions/efficientnet-b3_focal_512_1.00e-04.csv
# kaggle competitions submit -c alaska2-image-steganalysis -f
